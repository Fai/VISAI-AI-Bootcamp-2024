{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cf0bde8",
   "metadata": {},
   "source": [
    "# Lab 2: Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1122593a",
   "metadata": {},
   "source": [
    "## <u>Table of contents</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcab303a",
   "metadata": {},
   "source": [
    "### 1. Manipulation\n",
    "1. Data Structure and Input/Output Data <br>\n",
    "2. Getting Data and Modifying Data <br>\n",
    "3. Summary statistics and aggregating data <br>\n",
    "4. Merge and Append Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b041e0",
   "metadata": {},
   "source": [
    "### 2. Cleaning\n",
    "1. Outlier <br>\n",
    "2. Incorrect data type<br>\n",
    "3. Missing data<br>\n",
    "4. Duplicates<br>\n",
    "5. Inaccurate data/ Invalid category<br>\n",
    "6. Data Binning<br>\n",
    "7. Data encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c47be8",
   "metadata": {},
   "source": [
    "<b>Cheat sheet</b> <br>\n",
    "pandas: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b654e4",
   "metadata": {},
   "source": [
    "First, `import` is used to import modules in Python. <br>\n",
    "Python has many modules related to data manipulation. The most common modules are `numpy` and `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8664aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import modules, use these codes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # use for create graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe1cf6",
   "metadata": {},
   "source": [
    "## 1. Outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37e0358",
   "metadata": {},
   "source": [
    "<b> Do not forget to check and clean outlier. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf80f5e",
   "metadata": {},
   "source": [
    "The dataset we use in this session is a generate total sales dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9145bc38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales_data = pd.read_csv(\"./2_total_sales_column.csv\", sep=\"\\t\")\n",
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7187c1f",
   "metadata": {},
   "source": [
    "We can see preliminary data by creating statistics data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660973d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View descriptive statistics of data\n",
    "sales_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d39af9",
   "metadata": {},
   "source": [
    "And, we plot the boxplot by using `<DataFrame>.boxplot()`.<br><br>\n",
    "Doc df.boxplot: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b062b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View boxplot of data\n",
    "sales_data.boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d2a153",
   "metadata": {},
   "source": [
    "We will separate group of upper outliers and the other because this is total sales dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02292d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate group of upper outlier and the other\n",
    "cond1 = sales_data[\"# total_sales\"] > 2500\n",
    "upper = sales_data.loc[cond1, [\"# total_sales\"]]\n",
    "lower = sales_data.loc[~cond1, [\"# total_sales\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a7c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View boxplot of upper outliers\n",
    "upper.boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff19f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View boxplot of remaining data\n",
    "lower.boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcd0ccb",
   "metadata": {},
   "source": [
    "we do not remove lower outliers because we assume that we interested in returning a product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27f260",
   "metadata": {},
   "source": [
    "## 2. Incorrect data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cdfd8a",
   "metadata": {},
   "source": [
    "The dataset which we use in this session is a demo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90560c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data = pd.read_csv(\"./data/4_Demo_data.csv\")\n",
    "demo_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b9fc53",
   "metadata": {},
   "source": [
    "Check data dtype by using `<DataFrame>.info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b0217",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ddd4db",
   "metadata": {},
   "source": [
    "We can set index by using `<DataFrame>.set_index()`. <br><br>\n",
    "Doc. df.set_index: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c2350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data = demo_data.set_index(\"Index\")\n",
    "demo_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68d559",
   "metadata": {},
   "source": [
    "We can change the data into the `category` dtype by using `<DataFrame>.astype()`. <br><br>\n",
    "Doc. astype: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f632c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data[\"categorical\"] = demo_data[\"categorical\"].astype(\"category\")\n",
    "demo_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa57b8bf",
   "metadata": {},
   "source": [
    "We must handle `na` by changing it to `<numpy>.nan` by using `<DataFrame>.replace()`. <br><br>\n",
    "\n",
    "Doc. df.replace: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581929bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data = demo_data.replace(\"na\", np.nan)\n",
    "demo_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data[[\"feature1\", \"feature2\"]] = demo_data[[\"feature1\", \"feature2\"]].astype(\"float\")\n",
    "demo_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cdb378",
   "metadata": {},
   "source": [
    "We can also convert the argument into datetime by using `<pandas>.to_datetime()`.<br><br>\n",
    "Doc. pd.to_datetime: https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html <br>\n",
    "Doc. strftime format: https://strftime.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57e8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data[\"create_date\"] = pd.to_datetime(demo_data[\"create_date\"], format=\"%d-%b-%y\")\n",
    "demo_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a2bdec",
   "metadata": {},
   "source": [
    "## 3. Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de5ac45",
   "metadata": {},
   "source": [
    "We can check the number of missing data rows by using `<DataFrame>.info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638bbf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114b6db7",
   "metadata": {},
   "source": [
    "Or check each missing data row by using `<DataFrame>.isna()`. <br><br>\n",
    "Doc. df.isna: https://pandas.pydata.org/docs/reference/api/pandas.isna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5cded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1830c1f3",
   "metadata": {},
   "source": [
    "We can combine boolean DataFrame by using `<DataFrame>.all()` and `<DataFrame>.any()`.\n",
    "- `<DataFrame>.all()`: Return whether all elements are True, potentially over an axis.\n",
    "- `<DataFrame>.any()`: Return whether any element is True, potentially over an axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ffa3d3",
   "metadata": {},
   "source": [
    "Doc df.all: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.all.html <br>\n",
    "Doc df.any: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.any.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1182974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing = demo_data.isna().any(axis=1)\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c303b168",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View all rows which includes missing data\n",
    "demo_data[missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6153b78e",
   "metadata": {},
   "source": [
    "### 3.1. Deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f7731",
   "metadata": {},
   "source": [
    "We can remove missing data by using `<DataFrame>.dropna()` <br><br>\n",
    "Doc. df.dropna: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad935ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try deleting all missing data rows\n",
    "demo_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d16a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try deleting all missing data columns\n",
    "demo_data.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0fb2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try deleting specific missing data row\n",
    "demo_data.dropna(how=\"all\", subset=[\"feature1\", \"feature2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeeaab0",
   "metadata": {},
   "source": [
    "### 3.2. Substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae62dbb1",
   "metadata": {},
   "source": [
    "Fill the missing values by using the specified method `<DataFrame>.fillna()`<br><br>\n",
    "Doc. df.fillna: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cc401d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Try substituting with 0 (select only missing values)\n",
    "demo_data.fillna(0)[missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249f752",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Try substituting with median (select only missing values)\n",
    "demo_data.fillna(demo_data.median())[missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f8c2ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Try substituting with Last Observation Carried Forward (LOCF)/Next Observation Carried Backward (NOCB) (select only missing values)\n",
    "demo_data.fillna(method=\"ffill\")[missing]\n",
    "# demo_data.fillna(method=\"bfill\")[missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42316d63",
   "metadata": {},
   "source": [
    "We can substitute interporation for missing data by using `<DataFrame>.interpolate()`<br><br>\n",
    "Doc. df.interporate: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1453ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try substituting with interporate\n",
    "demo_data[\"feature1\"]= demo_data[\"feature1\"].fillna(demo_data[\"feature1\"].interpolate())\n",
    "demo_data[\"feature2\"] = demo_data[\"feature2\"].fillna(demo_data[\"feature2\"].interpolate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314eae5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select only missing values\n",
    "demo_data[missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8885ff",
   "metadata": {},
   "source": [
    "## 4. Duplicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c285c0",
   "metadata": {},
   "source": [
    "The dataset which we use in this session is a modified supermarket sales dataset. <br><br>\n",
    "Ref: https://www.kaggle.com/datasets/aungpyaeap/supermarket-sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86fade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "supermerket_data = pd.read_csv(\"./data/5_Supermarket_data_duplicate.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e18eec8",
   "metadata": {},
   "source": [
    "We can check the dupilcated index DataFrame by using `<DataFrame>.duplicated()` <br><br>\n",
    "Doc. df.duplicated: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad64ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "supermerket_data.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3918f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all duplicated rows\n",
    "supermerket_data[supermerket_data.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58129618",
   "metadata": {},
   "source": [
    "And we can remove dupilcated index DataFrame by using `<DataFrame>.drop_duplicates()`. <br><br> \n",
    "Doc. df.duplicate: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b8cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "supermerket_data = supermerket_data.drop_duplicates()\n",
    "supermerket_data[supermerket_data.duplicated(keep=False)] # View all duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6a1a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "supermerket_data.loc[supermerket_data[\"Invoice ID\"] == \"605-03-2706\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b52db69",
   "metadata": {},
   "source": [
    "Sometimes, we may want to group DataFrame index instead of removing the duplicated column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f5be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read duplicate csv file again\n",
    "supermerket_data = pd.read_csv(\"./data/5_Supermarket_data_duplicate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c2606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "supermerket_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b270b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "supermerket_groupby = supermerket_data.groupby(['Invoice ID', 'Branch', 'City', 'Customer type', 'Gender', 'Product line', 'Unit price'])\\\n",
    "                        .sum().reset_index()\n",
    "supermerket_groupby.loc[supermerket_groupby[\"Invoice ID\"] == \"605-03-2706\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932f83dc",
   "metadata": {},
   "source": [
    "## 5. Inaccurate data/ Invalid category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3d9f81",
   "metadata": {},
   "source": [
    "The dataset which we use in this session is a demo dataset. <br>\n",
    "Sometimes, categorical data has invalid category. We must remove it or change it to `np.NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db031ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame\n",
    "fruit_data = pd.DataFrame({\n",
    "    \"fruit\": [\"strawberry\", \"melon\", \"raisin\", \"cherry\", \"grape\", \"red apple\", \"lime\", \"pear\", \"raspberry\"],\n",
    "    \"color\": [\"red\", \"green\", \"purple\", \"red\", \"purple\", \"red\", \"sphere\", \"green\", \"red\"]\n",
    "})\n",
    "\n",
    "# copy DataFrame\n",
    "fruit_data1 = fruit_data.copy()\n",
    "fruit_data2 = fruit_data.copy()\n",
    "\n",
    "fruit_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b933328",
   "metadata": {},
   "source": [
    "We can return unique values of Series object by using `<Series>.unique()`. <br><br>\n",
    "Doc. s.unique: https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c50655",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_data[\"color\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc8ba36",
   "metadata": {},
   "source": [
    "### 5.1. Replace values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e78f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = fruit_data1[\"color\"] == \"sphere\"\n",
    "fruit_data1.loc[cond, \"color\"] = np.NaN\n",
    "fruit_data1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672851f5",
   "metadata": {},
   "source": [
    "### 5.2. Remove row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba0d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = fruit_data2[\"color\"] == \"sphere\"\n",
    "fruit_data2 = fruit_data2[~cond]\n",
    "fruit_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb3b7e6",
   "metadata": {},
   "source": [
    "## 6. Data binning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f981e",
   "metadata": {},
   "source": [
    "Data binning is the procress to reduce the effects of minor observation errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf9931e",
   "metadata": {},
   "source": [
    "The dataset which we use in this session is a modified solar generation and demand dataset. <br><br>\n",
    "Ref: https://www.kaggle.com/datasets/arielcedola/solar-generation-and-demand-italy-20152016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4420f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_data = pd.read_csv(\"./data/6_Solar_generation_and_demand_2015_modify.csv\")\n",
    "solar_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2ed681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only interesting column and drop duplicates index\n",
    "selected_solar_column = solar_data[\"IT_solar_generation\"].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ffab80",
   "metadata": {},
   "source": [
    "We can bin values into discrete intervals by using `<pandas>.cut()` <br><br>\n",
    "Doc. pd.cut: https://pandas.pydata.org/docs/reference/api/pandas.cut.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c807e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.cut(selected_solar_column, 4)\n",
    "pd.cut(selected_solar_column, 4).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d51eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(selected_solar_column, 4, labels=[\"low\", \"normal\", \"high\",  \"extreme\"])\n",
    "# pd.cut(selected_solar_column, 4, labels=[\"low\", \"normal\", \"high\",  \"extreme\"]).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e8ae73",
   "metadata": {},
   "source": [
    "We can bin values into quantile intervals by using `<pandas>.qcut()` <br><br>\n",
    "Doc. pd.qcut: https://pandas.pydata.org/docs/reference/api/pandas.qcut.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc16897",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(selected_solar_column, 4)\n",
    "# pd.qcut(selected_solar_column, 4).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2494cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(selected_solar_column, 4, labels=[\"q0-q1\", \"q1-q2\", \"q2-q3\", \"q3-q4\"])\n",
    "# pd.qcut(selected_solar_column, 4, labels=[\"q0-q1\", \"q1-q2\", \"q2-q3\", \"q3-q4\"]).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c386ba3",
   "metadata": {},
   "source": [
    "## 7. Data encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57da9d5d",
   "metadata": {},
   "source": [
    "Encoding is the process of converting data into a specified format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67a6cd9",
   "metadata": {},
   "source": [
    "The dataset which we use in this session is a demo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7731dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame\n",
    "fruit_data = pd.DataFrame({\n",
    "    \"fruit\": [\"strawberry\", \"melon\", \"raisin\", \"cherry\", \"grape\", \"red apple\", \"lime\", \"pear\", \"raspberry\"],\n",
    "    \"color\": [\"red\", \"green\", \"purple\", \"red\", \"purple\", \"red\", \"green\", \"green\", \"red\"]\n",
    "})\n",
    "\n",
    "# copy DataFrame\n",
    "fruit_data1 = fruit_data.copy()\n",
    "fruit_data2 = fruit_data.copy()\n",
    "\n",
    "fruit_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e91898",
   "metadata": {},
   "source": [
    "### 7.1. Ordinal encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0005e6f",
   "metadata": {},
   "source": [
    "First, we have to change `color` column to `category` dtype. <br>\n",
    "Then, use `<Series>.cat.codes` to return Series of codes. <br><br>\n",
    "doc s.cat.codes: https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.codes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab571492",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_data1[\"color\"] = fruit_data1[\"color\"].astype(\"category\")\n",
    "fruit_data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4abdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_data1[\"color_encode\"] = fruit_data1[\"color\"].cat.codes\n",
    "fruit_data1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86fb504",
   "metadata": {},
   "source": [
    "### 7.2. One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945792de",
   "metadata": {},
   "source": [
    "Use `<Pandas>.get_dummies()` to convert categorical variable into dummy/indicator variables. (Normally, we often remove the first level)<br><br>\n",
    "Doc pd.get_dummies: https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ce7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummie = pd.get_dummies(fruit_data[\"color\"], prefix=\"color\", drop_first=True)\n",
    "dummie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_data2 = pd.concat([fruit_data, dummie], axis=1)\n",
    "fruit_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da16af19",
   "metadata": {},
   "source": [
    "### <u>Exercise 5</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626e2779",
   "metadata": {},
   "source": [
    "The dataset which we use in this exercise is a chronic kidney disease dataset. <br><br>\n",
    "Ref: https://archive.ics.uci.edu/ml/datasets/chronic_kidney_disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5e6bca",
   "metadata": {},
   "source": [
    "<u><b>Metadata</b></u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eebe687",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <th><b>Variable</b></th>\n",
    "            <th><b>Definition</b></th>\n",
    "            <th><b>Remark</b></th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>age</td>\n",
    "            <td>age</td>\n",
    "            <td>numerical</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>bp</td>\n",
    "            <td>blood pressure</td>\n",
    "            <td>numerical</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>al</td>\n",
    "            <td>albumin</td>\n",
    "            <td>nominal (0,1,2,3,4,5)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>su</td>\n",
    "            <td>sugar</td>\n",
    "            <td>nominal (0,1,2,3,4,5)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>appet</td>\n",
    "            <td>appetite</td>\n",
    "            <td>nominal (0,1,2,3,4,5)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>pe</td>\n",
    "            <td>pedal edema</td>\n",
    "            <td>nominal (yes,no)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>ane</td>\n",
    "            <td>anemia</td>\n",
    "            <td>nominal (yes,no)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>class</td>\n",
    "            <td>class</td>\n",
    "            <td>nominal (ckd,notckd)</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec75af4e",
   "metadata": {},
   "source": [
    "Import `7_Chronic_kidney_disease` file and do the codings to clean data, and clean it the best you can. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030023b7",
   "metadata": {},
   "source": [
    "<b>Check list</b>\n",
    "- Outlier\n",
    "- Incorrect datatype\n",
    "- Missing data\n",
    "- Duplicates\n",
    "- Inaccurate data/ Invalid category\n",
    "- Data Binning\n",
    "- Data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c59fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for Exercise 5 is here\n",
    "# Load data\n",
    "data_5 = pd.read_csv(\"./data/7_Chronic_kidney_disease.csv\")\n",
    "data_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac459035",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
