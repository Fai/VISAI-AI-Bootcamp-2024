{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425c49a8",
   "metadata": {},
   "source": [
    "# Exercise solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e27ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import modules, use these codes\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f284a2",
   "metadata": {},
   "source": [
    "## <u>Exercise 1</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea16867",
   "metadata": {},
   "source": [
    "### <u>Exercise 1-1</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94488198",
   "metadata": {},
   "source": [
    "Import `1_Titanic_dataset_excel_1` file to this notebook and display the <b>first</b> 5 rows.\n",
    "- The file is available in the same file as the notebook.\n",
    "- Make `PassengerId` the DataFrame's index column name by using `index_col` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bc9963",
   "metadata": {},
   "source": [
    "<b>DataFrame Desired</b>\n",
    "<img src=\"./images/exercise1-1.png\" alt=\"exercise1-1\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e5ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for Exercise 1-1 is here\n",
    "data_1_1 = pd.read_excel(\"1_Titanic_dataset_excel_1.xlsx\", index_col=\"PassengerId\")\n",
    "data_1_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e8ce7",
   "metadata": {},
   "source": [
    "### <u>Exercise 1-2</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d01a52e",
   "metadata": {},
   "source": [
    "Import `Titanic_sheet` (located in the `1_Titanic_dataset_excel_2` file) to this notebook. <br>\n",
    "- The file is available in the data's folder. You have to use <b>relative path</b> as the parameter. \n",
    "- Make `PassengerId` the DataFrame's index column name by using `index_col` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code Exercise 1-2 is here\n",
    "data_1_2 = pd.read_excel(\"./data/1_Titanic_dataset_excel_2.xlsx\", index_col=\"PassengerId\", sheet_name=\"Titanic_sheet\", header=3)\n",
    "data_1_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874d8a7d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49a5d63",
   "metadata": {},
   "source": [
    "## <u>Exercise 2</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ccd49e",
   "metadata": {},
   "source": [
    "The dataset which we use in this exercise is a supermarket sales dataset. <br><br>\n",
    "Ref: https://www.kaggle.com/datasets/aungpyaeap/supermarket-sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f82eec",
   "metadata": {},
   "source": [
    "Import `2_Supermarket_data` file and run codings to solve the following question.\n",
    "1. Calculate the tax for each unit price. (Assuming all items have 7% tax)\n",
    "2. Calculate the total price for each product. (Tax included)\n",
    "3. Which store branch has the most total sales? (You can use `<DataFrame>.sum()` to sum in each column, if is possible.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for Exercise 2.1 is here\n",
    "data_2 = pd.read_csv(\"./Data/2_Supermarket_data.csv\")\n",
    "data_2[\"7%tax\"] = data_2[\"Unit price\"] * 0.07\n",
    "data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb5095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for Exercise 2.2 is here\n",
    "data_2[\"Total\"] = (data_2[\"Unit price\"] + data_2[\"7%tax\"])* data_2[\"Quantity\"]\n",
    "data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1323fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for Exercise 2.3 is here\n",
    "branch_a = data_2[data_2[\"Branch\"] == \"A\"][\"Total\"].sum()\n",
    "branch_b = data_2[data_2[\"Branch\"] == \"B\"][\"Total\"].sum()\n",
    "branch_c = data_2[data_2[\"Branch\"] == \"C\"][\"Total\"].sum()\n",
    "\n",
    "if (branch_a > branch_b) & (branch_a > branch_c):\n",
    "    print(\"Branch A is the most total sales.\")\n",
    "elif (branch_b > branch_a) & (branch_b > branch_c):\n",
    "    print(\"Branch B is the most total sales.\")\n",
    "else:\n",
    "    print(\"Branch C is the most total sales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fff34e8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269f3464",
   "metadata": {},
   "source": [
    "## <u>Exercise 3</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f569a",
   "metadata": {},
   "source": [
    "Import `1_Titanic_dataset_csv` file and do the codings to solve following question. <br>\n",
    "- What is the average, max, and min values of `Fare` for each `Sex`?\n",
    "- How many unique values of each `Pclass` are there? (sort by index labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bf4c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for Exercise 3.1 is here\n",
    "data_3 = pd.read_csv(\"./Data/1_Titanic_dataset_csv.csv\", index_col=\"PassengerId\")\n",
    "data_3[[\"Sex\", \"Fare\"]].groupby(\"Sex\").agg([np.average, np.min, np.max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836098be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for Exercise 3.2 is here\n",
    "data_3[\"Pclass\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3f743e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904b63cb",
   "metadata": {},
   "source": [
    "## <u>Exercise 4</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db9e366",
   "metadata": {},
   "source": [
    "Import `3_Customer_member_invoice`, `3_Customer_normal_invoice`, and `3_Sales_invoice` file and do the coding to solve following question. <br>\n",
    "- How many invoices do not have NaN data? (customer data and sales data included)\n",
    "- Save as a csv file titled '`3_exercise_4_data`' including a tab delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a68124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code for Exercise 4.1 is here\n",
    "data_4_cus_member = pd.read_csv(\"./data/3_Customer_member_invoice.csv\")\n",
    "data_4_cus_normal = pd.read_csv(\"./data/3_Customer_normal_invoice.csv\")\n",
    "data_4_sales = pd.read_excel(\"./data/3_Sales_invoice.xlsx\")\n",
    "\n",
    "data_4_cus_member.head()\n",
    "# data_4_cus_normal.head()\n",
    "# data_4_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec74cc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_4_customer = pd.concat([data_4_cus_member, data_4_cus_normal])\n",
    "data_4_merge = pd.merge(data_4_customer, data_4_sales, on=\"Invoice ID\")\n",
    "data_4_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d3b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{data_4_merge.shape[0]} row\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec1d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for Exercise 4.2 is here\n",
    "data_4_merge.to_csv(\"./data/3_exercise_4_data.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801607d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3363e98d",
   "metadata": {},
   "source": [
    "## <u>Exercise 5</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f725f6e",
   "metadata": {},
   "source": [
    "The dataset which we use in this exercise is a chronic kidney disease dataset. <br><br>\n",
    "Ref: https://archive.ics.uci.edu/ml/datasets/chronic_kidney_disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73353093",
   "metadata": {},
   "source": [
    "<u><b>Metadata</b></u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba6f92",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <th><b>Variable</b></th>\n",
    "            <th><b>Definition</b></th>\n",
    "            <th><b>Remark</b></th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>age</td>\n",
    "            <td>age</td>\n",
    "            <td>numerical</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>bp</td>\n",
    "            <td>blood pressure</td>\n",
    "            <td>numerical</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>al</td>\n",
    "            <td>albumin</td>\n",
    "            <td>nominal (0,1,2,3,4,5)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>su</td>\n",
    "            <td>sugar</td>\n",
    "            <td>nominal (0,1,2,3,4,5)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>appet</td>\n",
    "            <td>appetite</td>\n",
    "            <td>nominal (0,1,2,3,4,5)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>pe</td>\n",
    "            <td>pedal edema</td>\n",
    "            <td>nominal (yes,no)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>ane</td>\n",
    "            <td>anemia</td>\n",
    "            <td>nominal (yes,no)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>class</td>\n",
    "            <td>class</td>\n",
    "            <td>nominal (ckd,notckd)</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f25e4",
   "metadata": {},
   "source": [
    "Import `7_Chronic_kidney_disease` file and do the codings to clean data, and clean it the best you can. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bc3e5b",
   "metadata": {},
   "source": [
    "<b>Check list</b>\n",
    "- Outlier\n",
    "- Incorrect datatype\n",
    "- Missing data\n",
    "- Duplicates\n",
    "- Inaccurate data/ Invalid category\n",
    "- Data Binning\n",
    "- Data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for Exercise 5 is here\n",
    "# Load data\n",
    "data_5 = pd.read_csv(\"./data/7_Chronic_kidney_disease.csv\")\n",
    "data_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f3e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape and dtype\n",
    "display(data_5.shape)\n",
    "data_5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c406614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique data of each column\n",
    "for name in data_5.columns:\n",
    "    unique_val = data_5[name].unique()\n",
    "    print(f\"{name}\")\n",
    "    print(f\"{unique_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7fe58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove appet column because it is invalid category\n",
    "data_5 = data_5.drop(\"appet\", axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check value_counts of catergorical columns\n",
    "cat_col = [\"al\", \"su\", \"pe\", \"ane\", \"class\"]\n",
    "for name in cat_col:\n",
    "    unique_val = data_5[name].value_counts()\n",
    "    print(f\"{name}\")\n",
    "    print(f\"{unique_val} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282cf86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change \"?\" to np.NaN\n",
    "data_5 = data_5.replace(\"?\", np.NaN)\n",
    "\n",
    "# Change \"0\" to np.NaN in \"ane\" column\n",
    "data_5[\"ane\"] = data_5[\"ane\"].replace(\"0\", np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcfa12b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check duplicate index\n",
    "data_5[data_5.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate index\n",
    "data_5 = data_5.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55d34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "display(data_5.shape)\n",
    "data_5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dadfd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill np.NaN in [\"age\", \"bp\"](numerical) with median\n",
    "data_5[\"age\"] = data_5[\"age\"].fillna(data_5[\"age\"].median())\n",
    "data_5[\"bp\"] = data_5[\"bp\"].fillna(data_5[\"bp\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2892c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use np.NaN in [\"al\", \"su\"](catergorical) as a new catergory\n",
    "data_5[\"al\"] = data_5[\"al\"].fillna(-1)\n",
    "data_5[\"su\"] = data_5[\"su\"].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db43d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove np.NaN in [\"pe\", \"ane\", \"class\"](catergorical) because there are only a few of it.\n",
    "nan_check = data_5[data_5[[\"pe\", \"ane\", \"class\"]].isna().any(axis=1)]\n",
    "display(nan_check)\n",
    "data_5 = data_5[~data_5[[\"pe\", \"ane\", \"class\"]].isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd60140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data type\n",
    "data_5[[\"age\", \"bp\"]] = data_5[[\"age\", \"bp\"]].astype(int)\n",
    "data_5[[\"al\", \"su\", \"pe\", \"ane\", \"class\"]] = data_5[[\"al\", \"su\", \"pe\", \"ane\", \"class\"]].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb88620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding data in [\"pe\", \"ane\", \"class\"](2 types category) \n",
    "data_5[\"pe\"] = data_5[\"pe\"].cat.codes.astype(\"category\")\n",
    "data_5[\"ane\"] = data_5[\"ane\"].cat.codes.astype(\"category\")\n",
    "data_5[\"class\"] = data_5[\"class\"].cat.codes.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b1d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display data\n",
    "data_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b174ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "display(data_5.shape)\n",
    "display(data_5.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249480ba",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
